{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpl backend:  module://ipykernel.pylab.backend_inline\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable, Function\n",
    "from torchvision import models, transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"mpl backend: \", plt.get_backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_size = 512 * 2 * 2\n",
    "\n",
    "model_urls = {\n",
    "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(classifier_size, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "    'LITTLE': [32, 'M', 64, 'M', 128, 128, 'M', 256, 256, 'M', 256, 256, 'M']\n",
    "}\n",
    "\n",
    "\n",
    "def vgg11(pretrained=False, **kwargs):\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\")\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfg['A']), **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict( model_zoo.load_url(model_urls['vgg11']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg11_little(pretrained=False, **kwargs):\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfg['A'], batch_norm=False), **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['vgg11']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'model_best.pth.tar'\n",
      "=> loaded checkpoint 'model_best.pth.tar' (epoch 2)\n"
     ]
    }
   ],
   "source": [
    "vgg_pretrained = vgg11_little(num_classes=200)\n",
    "vgg_pretrained = vgg_pretrained.cuda()\n",
    "resume='model_best.pth.tar'\n",
    "if os.path.isfile(resume):\n",
    "    print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "    checkpoint = torch.load(resume)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_prec1 = checkpoint['best_prec1']\n",
    "    vgg_pretrained.load_state_dict(checkpoint['state_dict'])\n",
    "    #optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "          .format(resume, checkpoint['epoch']))\n",
    "else:\n",
    "    print(\"=> no checkpoint found at '{}'\".format(resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_size = 512 * 2 * 2\n",
    "\n",
    "class vgg_conv(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, features, m_classes=1000):\n",
    "        super(vgg_conv, self).__init__()\n",
    "        # VGG16 (using return_indices=True on the MaxPool2d layers)\n",
    "        self.features = torch.nn.Sequential(\n",
    "            # conv1\n",
    "            torch.nn.Conv2d(3, 64, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "            # conv2\n",
    "            torch.nn.Conv2d(64, 128, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "            # conv3\n",
    "            torch.nn.Conv2d(128, 256, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(256, 256, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "            # conv4\n",
    "            torch.nn.Conv2d(512, 512, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(512, 512, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "            # conv5\n",
    "            torch.nn.Conv2d(512, 512, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(512, 512, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, return_indices=True))\n",
    "        self.feature_outputs = [0]*len(self.features)\n",
    "        self.pool_indices = dict()\n",
    "\n",
    "        self.classifier = vgg_pretrained.classifier\n",
    "        self._initialize_weights()\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # initializing weights using ImageNet-trained model from PyTorch\n",
    "        for i, layer in enumerate(vgg_pretrained.features):\n",
    "            print(\"initializing layer {}: {}\".format(i, layer))\n",
    "            try:\n",
    "                self.features[i].weight.data = layer.weight.data\n",
    "                self.features[i].bias.data = layer.bias.data\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    def get_conv_layer_indices(self):\n",
    "        return [0, 3, 6, 8, 11, 13, 16, 18]\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        output = x\n",
    "        for i, layer in enumerate(self.features):\n",
    "            if isinstance(layer, torch.nn.MaxPool2d):\n",
    "                output, indices = layer(output)\n",
    "                self.feature_outputs[i] = output\n",
    "                self.pool_indices[i] = indices\n",
    "            else:\n",
    "                output = layer(output)\n",
    "                self.feature_outputs[i] = output\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class vgg_deconv(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vgg_deconv, self).__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.conv2DeconvIdx = {0:12, 3:10, 6:8, 8:7, 11:5, 13:4, 16:2, 18:1}\n",
    "        self.conv2DeconvBiasIdx = {0:10, 3:8, 6:7, 8:5, 11:4, 13:2, 16:1, 18:0}\n",
    "        self.unpool2PoolIdx = {0:20, 3:15, 6:10, 9:5, 11:2}\n",
    "        \n",
    "        self.deconv_features = torch.nn.Sequential(\n",
    "            torch.nn.MaxUnpool2d(2, stride=2),\n",
    "            torch.nn.ConvTranspose2d(512, 512, 3, padding=1),\n",
    "            torch.nn.ConvTranspose2d(512, 512, 3, padding=1),\n",
    "            torch.nn.MaxUnpool2d(2, stride=2),\n",
    "            torch.nn.ConvTranspose2d(512, 512, 3, padding=1),\n",
    "            torch.nn.ConvTranspose2d(512, 512, 3, padding=1),\n",
    "            torch.nn.MaxUnpool2d(2, stride=2),\n",
    "            torch.nn.ConvTranspose2d(256, 256, 3, padding=1),\n",
    "            torch.nn.ConvTranspose2d(256, 128, 3, padding=1),\n",
    "            torch.nn.MaxUnpool2d(2, stride=2),\n",
    "            torch.nn.ConvTranspose2d(128, 64, 3, padding=1),\n",
    "            torch.nn.MaxUnpool2d(2, stride=2),\n",
    "            torch.nn.ConvTranspose2d(64, 3, 3, padding=1))\n",
    "\n",
    "        # not the most elegant, given that I don't need the MaxUnpools here\n",
    "        self.deconv_first_layers = torch.nn.ModuleList([\n",
    "            torch.nn.MaxUnpool2d(2, stride=2),\n",
    "            torch.nn.ConvTranspose2d(1, 512, 3, padding=1),\n",
    "            torch.nn.ConvTranspose2d(1, 512, 3, padding=1),\n",
    "            torch.nn.MaxUnpool2d(2, stride=2),\n",
    "            torch.nn.ConvTranspose2d(1, 512, 3, padding=1),\n",
    "            torch.nn.ConvTranspose2d(1, 512, 3, padding=1),\n",
    "            torch.nn.MaxUnpool2d(2, stride=2),\n",
    "            torch.nn.ConvTranspose2d(1, 256, 3, padding=1),\n",
    "            torch.nn.ConvTranspose2d(1, 128, 3, padding=1),\n",
    "            torch.nn.MaxUnpool2d(2, stride=2),\n",
    "            torch.nn.ConvTranspose2d(1, 64, 3, padding=1),\n",
    "            torch.nn.MaxUnpool2d(2, stride=2),\n",
    "            torch.nn.ConvTranspose2d(1, 3, 3, padding=1)])\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # initializing weights using ImageNet-trained model from PyTorch\n",
    "        for i, layer in enumerate(vgg_pretrained.features):\n",
    "            if isinstance(layer, torch.nn.Conv2d):\n",
    "                self.deconv_features[self.conv2DeconvIdx[i]].weight.data = layer.weight.data\n",
    "                biasIdx = self.conv2DeconvBiasIdx[i]\n",
    "                if biasIdx > 0:\n",
    "                    self.deconv_features[biasIdx].bias.data = layer.bias.data\n",
    "                \n",
    "\n",
    "    def forward(self, x, layer_number, map_number, pool_indices):\n",
    "        start_idx = self.conv2DeconvIdx[layer_number]\n",
    "        if not isinstance(self.deconv_first_layers[start_idx], torch.nn.ConvTranspose2d):\n",
    "            raise ValueError('Layer '+str(layer_number)+' is not of type Conv2d')\n",
    "        # set weight and bias\n",
    "        self.deconv_first_layers[start_idx].weight.data = self.deconv_features[start_idx].weight[map_number].data[None, :, :, :]\n",
    "        self.deconv_first_layers[start_idx].bias.data = self.deconv_features[start_idx].bias.data        \n",
    "        # first layer will be single channeled, since we're picking a particular filter\n",
    "        output = self.deconv_first_layers[start_idx](x)\n",
    "\n",
    "        # transpose conv through the rest of the network\n",
    "        for i in range(start_idx+1, len(self.deconv_features)):\n",
    "            if isinstance(self.deconv_features[i], torch.nn.MaxUnpool2d):\n",
    "                output = self.deconv_features[i](output, pool_indices[self.unpool2PoolIdx[i]])\n",
    "            else:\n",
    "                output = self.deconv_features[i](output)\n",
    "                if i != len(self.deconv_features)-1:\n",
    "                    output = self.relu(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing layer 0: Conv2d (3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "initializing layer 1: ReLU(inplace)\n",
      "initializing layer 2: MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "initializing layer 3: Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "initializing layer 4: ReLU(inplace)\n",
      "initializing layer 5: MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "initializing layer 6: Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "initializing layer 7: ReLU(inplace)\n",
      "initializing layer 8: Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "initializing layer 9: ReLU(inplace)\n",
      "initializing layer 10: MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "initializing layer 11: Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "initializing layer 12: ReLU(inplace)\n",
      "initializing layer 13: Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "initializing layer 14: ReLU(inplace)\n",
      "initializing layer 15: MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "initializing layer 16: Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "initializing layer 17: ReLU(inplace)\n",
      "initializing layer 18: Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "initializing layer 19: ReLU(inplace)\n",
      "initializing layer 20: MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "vgg_c = vgg_conv(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def it(layers, features):\n",
    "    for i in layers:\n",
    "        yield i, features[i]\n",
    "def enumerate_shift(shift, iterable):\n",
    "    for i, v in enumerate(iterable):\n",
    "        if i >= shift:\n",
    "            yield i, v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d (3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (3): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (6): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (11): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace)\n",
       "    (13): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace)\n",
       "    (15): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (16): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace)\n",
       "    (20): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=4096)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=200)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [9, 10, 12, 16, 20, 22, 25, 27, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63], 3: [4, 14, 15, 20, 25, 28, 40, 41, 42, 47, 55, 61, 62, 65, 81, 83, 84, 85, 86, 88, 90, 93, 95, 97, 105, 107, 111, 114, 115], 6: [24, 26, 42, 45, 53, 64, 67, 69, 73, 75, 80, 81, 84, 85, 86, 87, 89, 91, 94, 95, 97, 98, 107, 110, 111, 116, 117, 120, 124, 125, 132, 135, 136, 139, 144, 146, 149, 150, 152, 157, 158, 161, 164, 165, 166, 168, 169, 170, 171, 179, 181, 183, 184, 185, 186, 189, 191, 193, 194, 195, 196, 197, 198, 200, 203, 204, 207, 209, 210, 213, 215, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252]}\n",
      "3 [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 14, 15, 17, 18, 19, 21, 23, 24, 26, 28, 29, 33, 36, 44, 47, 49, 57]\n",
      "\n",
      "6 [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 87, 89, 91, 92, 94, 96, 98, 99, 100, 101, 102, 103, 104, 106, 108, 109, 110, 112, 113, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127]\n",
      "\n",
      "0 [0, 1, 2]\n",
      "\n",
      "8 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 70, 71, 72, 74, 76, 77, 78, 79, 82, 83, 88, 90, 92, 93, 96, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 112, 113, 114, 115, 118, 119, 121, 122, 123, 126, 127, 128, 129, 130, 131, 133, 134, 137, 138, 140, 141, 142, 143, 145, 147, 148, 151, 153, 154, 155, 156, 159, 160, 162, 163, 167, 172, 173, 174, 175, 176, 177, 178, 180, 182, 187, 188, 190, 192, 199, 201, 202, 205, 206, 208, 211, 212, 214, 221, 239, 241, 250, 253, 254, 255]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers_to_process = [0, 3, 6]\n",
    "n_filters = {0: 64, 3: 128, 6: 256}\n",
    "\n",
    "keep_filter_indices = {0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 14, 15, 17, 18, 19, 21, 23, 24, 26, 28, 29, 33, 36, 44, 47, 49, 57], \n",
    "                       3:[0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 87, 89, 91, 92, 94, 96, 98, 99, 100, 101, 102, 103, 104, 106, 108, 109, 110, 112, 113, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127], \n",
    "                       6: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 70, 71, 72, 74, 76, 77, 78, 79, 82, 83, 88, 90, 92, 93, 96, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 112, 113, 114, 115, 118, 119, 121, 122, 123, 126, 127, 128, 129, 130, 131, 133, 134, 137, 138, 140, 141, 142, 143, 145, 147, 148, 151, 153, 154, 155, 156, 159, 160, 162, 163, 167, 172, 173, 174, 175, 176, 177, 178, 180, 182, 187, 188, 190, 192, 199, 201, 202, 205, 206, 208, 211, 212, 214, 221, 239, 241, 250, 253, 254, 255]}\n",
    "remove_filter_indices = {layer_i: [j for j in range(n_filters[layer_i]) if not j in keep_i] for layer_i, keep_i in keep_filter_indices.items()}\n",
    "#remove_filter_indices = {0: [1,2,3], 3: [1,2,3], 6: [1,2,3]}\n",
    "\n",
    "print(remove_filter_indices)\n",
    "remove_num_filt = {k:len(v) for k, v in remove_filter_indices.items()}\n",
    "filt_f = lambda l: lambda x: not x in l\n",
    "indices = {k: list(filter(filt_f(remove_filter_indices[k]), range(v.weight.data.shape[0]))) for k, v in it(layers_to_process, vgg_pretrained.features)}\n",
    "indices_in = {k: list(filter(filt_f(remove_filter_indices[layers_to_process[i-1]]), range(v.weight.data.shape[1]))) for i, (k, v) in enumerate_shift(1, it(layers_to_process, vgg_pretrained.features))}\n",
    "indices_in[0] = [0, 1, 2]\n",
    "indices_in[8] = indices[6]\n",
    "last_layer = 256\n",
    "indices[8] = list(range(last_layer))\n",
    "for i, j in indices_in.items():\n",
    "    #print(i, remove_num_filt[i], len(indices[i]), len(indices_in[i]))\n",
    "    print(i, indices_in[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VGG16_conv_rem(torch.nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(VGG16_conv_rem, self).__init__()\n",
    "        # VGG16 (using return_indices=True on the MaxPool2d layers)\n",
    "        self.features = torch.nn.Sequential(\n",
    "            # conv1\n",
    "            torch.nn.Conv2d(len(indices_in[0]), len(indices[0]), 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "            # conv2\n",
    "            torch.nn.Conv2d(len(indices_in[3]), len(indices[3]), 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "            # conv3\n",
    "            torch.nn.Conv2d(len(indices_in[6]), len(indices[6]), 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(len(indices[6]), 256, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "            # conv4\n",
    "            torch.nn.Conv2d(512, 512, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(512, 512, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, return_indices=True),\n",
    "            # conv5\n",
    "            torch.nn.Conv2d(512, 512, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(512, 512, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, stride=2, return_indices=True))\n",
    "        self.feature_outputs = [0]*len(self.features)\n",
    "        self.pool_indices = dict()\n",
    "\n",
    "        self.classifier = vgg_pretrained.classifier\n",
    "        self._initialize_weights()\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # initializing weights using ImageNet-trained model from PyTorch\n",
    "        for i, layer in enumerate(vgg_pretrained.features):\n",
    "            print(\"initializing layer {}: {}\".format(i, layer))\n",
    "            try:\n",
    "                if i in layers_to_process or i == 8:\n",
    "                    print(\"        HERE1: \", i, self.features[i].weight.data.shape)\n",
    "                    print(\"        HERE2: \", i, layer.weight.data[indices[i],][:,indices_in[i],].shape)\n",
    "                    \n",
    "                    self.features[i].weight.data = layer.weight.data[indices[i],][:,indices_in[i],]\n",
    "                    self.features[i].bias.data = layer.bias.data[indices[i],]\n",
    "                else:\n",
    "                    self.features[i].weight.data = layer.weight.data\n",
    "                    self.features[i].bias.data = layer.bias.data\n",
    "            except Exception as e:\n",
    "                print(\"    E: \", i, e)\n",
    "                continue\n",
    "\n",
    "    def get_conv_layer_indices(self):\n",
    "        return [0, 3, 6, 8, 11, 13, 16, 18]\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        output = x\n",
    "        for i, layer in enumerate(self.features):\n",
    "            if isinstance(layer, torch.nn.MaxPool2d):\n",
    "                output, indices = layer(output)\n",
    "                self.feature_outputs[i] = output\n",
    "                self.pool_indices[i] = indices\n",
    "            else:\n",
    "                output = layer(output)\n",
    "                self.feature_outputs[i] = output\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing layer 0: Conv2d (3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        HERE1:  0 torch.Size([28, 3, 3, 3])\n",
      "        HERE2:  0 torch.Size([28, 3, 3, 3])\n",
      "initializing layer 1: ReLU(inplace)\n",
      "    E:  1 'ReLU' object has no attribute 'weight'\n",
      "initializing layer 2: MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    E:  2 'MaxPool2d' object has no attribute 'weight'\n",
      "initializing layer 3: Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        HERE1:  3 torch.Size([99, 28, 3, 3])\n",
      "        HERE2:  3 torch.Size([99, 28, 3, 3])\n",
      "initializing layer 4: ReLU(inplace)\n",
      "    E:  4 'ReLU' object has no attribute 'weight'\n",
      "initializing layer 5: MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    E:  5 'MaxPool2d' object has no attribute 'weight'\n",
      "initializing layer 6: Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        HERE1:  6 torch.Size([152, 99, 3, 3])\n",
      "        HERE2:  6 torch.Size([152, 99, 3, 3])\n",
      "initializing layer 7: ReLU(inplace)\n",
      "    E:  7 'ReLU' object has no attribute 'weight'\n",
      "initializing layer 8: Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        HERE1:  8 torch.Size([256, 152, 3, 3])\n",
      "        HERE2:  8 torch.Size([256, 152, 3, 3])\n",
      "initializing layer 9: ReLU(inplace)\n",
      "    E:  9 'ReLU' object has no attribute 'weight'\n",
      "initializing layer 10: MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    E:  10 'MaxPool2d' object has no attribute 'weight'\n",
      "initializing layer 11: Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "initializing layer 12: ReLU(inplace)\n",
      "    E:  12 'ReLU' object has no attribute 'weight'\n",
      "initializing layer 13: Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "initializing layer 14: ReLU(inplace)\n",
      "    E:  14 'ReLU' object has no attribute 'weight'\n",
      "initializing layer 15: MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    E:  15 'MaxPool2d' object has no attribute 'weight'\n",
      "initializing layer 16: Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "initializing layer 17: ReLU(inplace)\n",
      "    E:  17 'ReLU' object has no attribute 'weight'\n",
      "initializing layer 18: Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "initializing layer 19: ReLU(inplace)\n",
      "    E:  19 'ReLU' object has no attribute 'weight'\n",
      "initializing layer 20: MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    E:  20 'MaxPool2d' object has no attribute 'weight'\n"
     ]
    }
   ],
   "source": [
    "x = VGG16_conv_rem(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16_conv_rem(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d (3, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (3): Conv2d (28, 99, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (6): Conv2d (99, 152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d (152, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (11): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU()\n",
       "    (13): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU()\n",
       "    (15): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (16): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU()\n",
       "    (18): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU()\n",
       "    (20): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=4096)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=200)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_checkpoint({\n",
    "        'epoch': 1,\n",
    "        'arch': 'vgg11_little_rem_filt',\n",
    "        'state_dict': x.state_dict(),\n",
    "        'best_prec1': 0,\n",
    "    }, \"vgg11_little_rem_filt.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
